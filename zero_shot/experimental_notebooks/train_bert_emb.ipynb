{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [00:22<00:00, 18.0MB/s] \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet pepper \t cucumber \t 0.1442\n",
      "sweet pepper \t truck \t 0.0354\n",
      "sweet pepper \t cat \t -0.0599\n",
      "sweet pepper \t plane \t 0.0221\n",
      "sweet pepper \t dog \t 0.0780\n",
      "sweet pepper \t shark \t -0.0224\n",
      "cucumber \t truck \t 0.2105\n",
      "cucumber \t cat \t 0.0533\n",
      "cucumber \t plane \t -0.0293\n",
      "cucumber \t dog \t 0.2014\n",
      "cucumber \t shark \t 0.1034\n",
      "truck \t cat \t 0.0662\n",
      "truck \t plane \t 0.2145\n",
      "truck \t dog \t 0.1941\n",
      "truck \t shark \t 0.0646\n",
      "cat \t plane \t 0.0790\n",
      "cat \t dog \t 0.1464\n",
      "cat \t shark \t 0.2491\n",
      "plane \t dog \t 0.0813\n",
      "plane \t shark \t 0.0806\n",
      "dog \t shark \t 0.2612\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-bert-base')\n",
    "\n",
    "sentences = [\"sweet pepper\", \"cucumber\", \"truck\", \"cat\", \"plane\", \"dog\", \"shark\"\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "# #Sort list by the highest cosine similarity score\n",
    "# all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
