{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid',\n",
       " 'annotations',\n",
       " 'annotations.tar.gz',\n",
       " 'images',\n",
       " 'images.tar.gz',\n",
       " 'test',\n",
       " 'train']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/usr0/home/gis/research/vis_lang/data/oxford_pets\"\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(path):\n",
    "    image_names = []\n",
    "    with open(path, 'r') as handle:\n",
    "        for line in handle:\n",
    "            image_name, _, _, _ = line.strip().split(' ')\n",
    "            image_names.append(image_name)\n",
    "    return image_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3680, 3669)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval_annotations = read_annotations(os.path.join(data_dir, 'annotations', 'trainval.txt'))\n",
    "test_annotations = read_annotations(os.path.join(data_dir, 'annotations', 'test.txt'))\n",
    "len(trainval_annotations), len(test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7393, 'american_bulldog_75.jpg')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files = os.listdir(os.path.join(data_dir, 'images'))\n",
    "len(image_files), image_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class2ids(annotations):\n",
    "    class2ids = {}\n",
    "    for annotation in annotations:\n",
    "        components = annotation.split('_')\n",
    "        label = '_'.join(components[:-1])\n",
    "        ref = components[-1]\n",
    "        if label not in class2ids:\n",
    "            class2ids[label] = []\n",
    "        class2ids[label].append(ref)\n",
    "    return class2ids\n",
    "\n",
    "def create_filenames(label, ids):\n",
    "    filenames = []\n",
    "    for ref in ids:\n",
    "        filename = f'{label}_{ref}.jpg'\n",
    "        filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "def split_partition(class2ids, proportion=.5):\n",
    "    split1, split2 = defaultdict(lambda: []), defaultdict(lambda: [])\n",
    "    for label, ids in class2ids.items():\n",
    "        np.random.shuffle(ids)\n",
    "        split_bound = int(len(ids) * proportion)\n",
    "        split1_files = create_filenames(label, ids[:split_bound])\n",
    "        split2_files = create_filenames(label, ids[split_bound:])\n",
    "        split1[label] = split1_files\n",
    "        split2[label]= split2_files\n",
    "    return split1, split2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval_class2ids = assign_class2ids(trainval_annotations)\n",
    "test_class2ids = assign_class2ids(test_annotations)\n",
    "len(trainval_class2ids), len(test_class2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, val_set = split_partition(trainval_class2ids, proportion=.5)\n",
    "test_set, _ = split_partition(test_class2ids, proportion=1.)\n",
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinian',\n",
       " 'american_bulldog',\n",
       " 'american_pit_bull_terrier',\n",
       " 'basset_hound',\n",
       " 'beagle']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_set.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set['Abyssinian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_structures(dataset, save_dir, source_dir):\n",
    "    for label, filenames in dataset.items():\n",
    "        label_dir = os.path.join(save_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        for filename in filenames:\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            dest_file = os.path.join(label_dir, filename)\n",
    "            copyfile(source_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file_structures(\n",
    "    train_set, \n",
    "    save_dir=os.path.join(data_dir, 'train'),\n",
    "    source_dir=os.path.join(data_dir, 'images')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file_structures(\n",
    "    val_set, \n",
    "    save_dir=os.path.join(data_dir, 'valid'),\n",
    "    source_dir=os.path.join(data_dir, 'images')\n",
    ")\n",
    "create_file_structures(\n",
    "    test_set, \n",
    "    save_dir=os.path.join(data_dir, 'test'),\n",
    "    source_dir=os.path.join(data_dir, 'images')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid',\n",
       " 'annotations',\n",
       " 'annotations.tar.gz',\n",
       " 'images',\n",
       " 'images.tar.gz',\n",
       " 'test',\n",
       " 'train']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinian',\n",
       " 'Bengal',\n",
       " 'Birman',\n",
       " 'Bombay',\n",
       " 'British_Shorthair',\n",
       " 'Egyptian_Mau',\n",
       " 'Maine_Coon',\n",
       " 'Persian',\n",
       " 'Ragdoll',\n",
       " 'Russian_Blue',\n",
       " 'Siamese',\n",
       " 'Sphynx',\n",
       " 'american_bulldog',\n",
       " 'american_pit_bull_terrier',\n",
       " 'basset_hound',\n",
       " 'beagle',\n",
       " 'boxer',\n",
       " 'chihuahua',\n",
       " 'english_cocker_spaniel',\n",
       " 'english_setter',\n",
       " 'german_shorthaired',\n",
       " 'great_pyrenees',\n",
       " 'havanese',\n",
       " 'japanese_chin',\n",
       " 'keeshond',\n",
       " 'leonberger',\n",
       " 'miniature_pinscher',\n",
       " 'newfoundland',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'saint_bernard',\n",
       " 'samoyed',\n",
       " 'scottish_terrier',\n",
       " 'shiba_inu',\n",
       " 'staffordshire_bull_terrier',\n",
       " 'wheaten_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(os.path.join(data_dir, 'train')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Initial Zero Shot Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import json\n",
    "\n",
    "from datasets import *\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import seaborn as sn\n",
    "\n",
    "from columnar import columnar\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_zero_shot(\n",
    "    loader,\n",
    "    classes,\n",
    "    zeroshot_weights,\n",
    "    clip_model_name=\"ViT-B/32\",\n",
    "):\n",
    "\n",
    "    global clip_model, clip_preprocess\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def accuracy(output, target, topk=(1,)):\n",
    "        pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        return [\n",
    "            float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())\n",
    "            for k in topk\n",
    "        ]\n",
    "\n",
    "    # lazy load\n",
    "    if clip_model == None:\n",
    "        clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "    per_class_accuracy_top1 = { k:[0,0, classes[k]] for k in range(len(classes))} # correct, total, class_name\n",
    "    per_class_accuracy_top5 = { k:[0,0, classes[k]] for k in range(len(classes))} \n",
    "\n",
    "    with torch.no_grad():\n",
    "        top1, top5, n = 0.0, 0.0, 0.0\n",
    "        for i , (images, target) in enumerate(tqdm(loader)):\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # predict\n",
    "            image_features = clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            logits = 100.0 * image_features @ zeroshot_weights\n",
    "\n",
    "            # measure accuracy\n",
    "            acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "            top1 += acc1\n",
    "            top5 += acc5\n",
    "            n += images.size(0)\n",
    "            \n",
    "            per_class_accuracy_top1[target.cpu().detach().numpy()[0]][0]+= acc1\n",
    "            per_class_accuracy_top1[target.cpu().detach().numpy()[0]][1]+= 1\n",
    "\n",
    "    top1 = (top1 / n) * 100\n",
    "    top5 = (top5 / n) * 100\n",
    "\n",
    "    return top1, per_class_accuracy_top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj = OxfordPets(4, 1, root='/usr0/home/gis/research/vis_lang/data/')\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", )\n",
    "train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "test_loader = dataset_obj.get_test_loader(transform_fn=clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2093b83a6754539aad92d4854ab464b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.05369310438812\n"
     ]
    }
   ],
   "source": [
    "phrase_file = \"/home/gis/research/vis_lang/efficient_finetuning/configs/phrases/pets.txt\"\n",
    "\n",
    "templates = []\n",
    "with open(phrase_file) as f:\n",
    "    templates = [line for line in f]\n",
    "    \n",
    "    def zeroshot_classifier(classnames, templates):\n",
    "        with torch.no_grad():\n",
    "            zeroshot_weights = []\n",
    "            for classname in classnames:\n",
    "                classname = ' '.join(classname.split('_'))\n",
    "                texts = [\n",
    "                    template.format(classname) for template in templates\n",
    "                ]  # format with class\n",
    "                texts = clip.tokenize(texts).cuda()  # tokenize\n",
    "                class_embeddings = clip_model.encode_text(texts)  # embed with text encoder\n",
    "                class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "                class_embedding = class_embeddings.mean(dim=0)\n",
    "                class_embedding /= class_embedding.norm()\n",
    "                zeroshot_weights.append(class_embedding)\n",
    "            zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "        return zeroshot_weights\n",
    "\n",
    "baseline_zw = zeroshot_classifier(dataset_obj.classes,templates)\n",
    "\n",
    "baseline_czs = clip_zero_shot(\n",
    "    test_loader,\n",
    "    dataset_obj.classes,\n",
    "    baseline_zw\n",
    ")\n",
    "print(baseline_czs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'British_Shorthair',\n",
       " 'Egyptian_Mau',\n",
       " 'Maine_Coon',\n",
       " 'Russian_Blue',\n",
       " 'american_bulldog',\n",
       " 'american_pit_bull_terrier',\n",
       " 'basset_hound',\n",
       " 'english_cocker_spaniel',\n",
       " 'english_setter',\n",
       " 'german_shorthaired',\n",
       " 'great_pyrenees',\n",
       " 'japanese_chin',\n",
       " 'miniature_pinscher',\n",
       " 'saint_bernard',\n",
       " 'scottish_terrier',\n",
       " 'shiba_inu',\n",
       " 'staffordshire_bull_terrier',\n",
       " 'wheaten_terrier',\n",
       " 'yorkshire_terrier'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(os.listdir(os.path.join(data_dir, 'test'))) - set(dataset_obj.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 35)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(data_dir, 'test'))), len(dataset_obj.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
