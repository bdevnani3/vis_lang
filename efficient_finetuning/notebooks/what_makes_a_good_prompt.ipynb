{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import json\n",
    "\n",
    "from datasets import *\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import seaborn as sn\n",
    "\n",
    "from columnar import columnar\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clip_zero_shot(\n",
    "    loader,\n",
    "    classes,\n",
    "    zeroshot_weights,\n",
    "    clip_model_name=\"ViT-B/32\",\n",
    "):\n",
    "\n",
    "    global clip_model, clip_preprocess\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def accuracy(output, target, topk=(1,)):\n",
    "        pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        return [\n",
    "            float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())\n",
    "            for k in topk\n",
    "        ]\n",
    "\n",
    "    # lazy load\n",
    "    if clip_model == None:\n",
    "        clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "        \n",
    "    per_class_accuracy_top1 = { k:[0,0, classes[k]] for k in range(len(classes))} # correct, total, class_name\n",
    "    per_class_accuracy_top5 = { k:[0,0, classes[k]] for k in range(len(classes))} \n",
    "\n",
    "    with torch.no_grad():\n",
    "        top1, top5, n = 0.0, 0.0, 0.0\n",
    "        for i , (images, target) in enumerate(tqdm(loader)):\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # predict\n",
    "            image_features = clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            logits = 100.0 * image_features @ zeroshot_weights\n",
    "\n",
    "            # measure accuracy\n",
    "            acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "            top1 += acc1\n",
    "            top5 += acc5\n",
    "            n += images.size(0)\n",
    "            \n",
    "            per_class_accuracy_top1[target.cpu().detach().numpy()[0]][0]+= acc1\n",
    "            per_class_accuracy_top1[target.cpu().detach().numpy()[0]][1]+= 1\n",
    "\n",
    "    top1 = (top1 / n) * 100\n",
    "    top5 = (top5 / n) * 100\n",
    "\n",
    "    return top1, per_class_accuracy_top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", )\n",
    "\n",
    "flowers = Flowers102(4, 1, '/nethome/bdevnani3/raid/data/')\n",
    "f_train_loader, _ = flowers.get_train_loaders(transform_fn=clip_preprocess)\n",
    "f_test_loader = flowers.get_test_loader(transform_fn=clip_preprocess)\n",
    "\n",
    "pets = OxfordPets(4, 1, '/nethome/bdevnani3/raid/data/')\n",
    "p_train_loader, _ = pets.get_train_loaders(transform_fn=clip_preprocess)\n",
    "p_test_loader = pets.get_test_loader(transform_fn=clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def per_class_performance(d, print_out=True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    corr = []\n",
    "    tot = []\n",
    "    for el in d:\n",
    "        x.append((d[el][0]*100)/d[el][1])\n",
    "        labels.append(d[el][2])\n",
    "        corr.append(d[el][0])\n",
    "        tot.append(d[el][1])\n",
    "    idx = np.argsort(x)\n",
    "    x = np.array(x)[idx]\n",
    "    labels = np.array(labels)[idx]\n",
    "    corr = np.array(corr)[idx]\n",
    "    tot = np.array(tot)[idx]\n",
    "    out = {}\n",
    "    for l,per,c,t in zip(labels,x,corr,tot):\n",
    "        out[l] = [np.around(per,5),int(c),int(t)]\n",
    "    if print_out:\n",
    "        table = columnar([[l, o[0], o[1], o[2]] for l,o in out.items()], [\"Class Name\", \"Accuracy(%)\", \"Num Correct\", \"Total\"])\n",
    "        print(table)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def relative_per_class_performance(d1,d2, print_out=True):\n",
    "    \"Positive value means d1 did better\"\n",
    "    x1 = []\n",
    "    labels = []\n",
    "    x2 = []\n",
    "    tot_num_labels_difference = 0\n",
    "    for el in d1:\n",
    "        x1.append(((d1[el][0]-d2[el][0])*100)/(d2[el][0]+0.0000001))\n",
    "        labels.append(d1[el][2])\n",
    "        num_labels_difference = d1[el][0]\n",
    "        num_labels_difference -= d2[el][0]\n",
    "        x2.append(num_labels_difference)\n",
    "        tot_num_labels_difference += num_labels_difference\n",
    "        \n",
    "#         x2.append((d2[el][0]*100)/d2[el][1])\n",
    "        \n",
    "#     final = np.array(x1)-np.array(x2)\n",
    "    idx = np.argsort(x1)\n",
    "    x1 = np.array(x1)[idx]\n",
    "    x2 = np.array(x2)[idx]\n",
    "    labels = np.array(labels)[idx]\n",
    "    out = {}\n",
    "    for l,per,num_per in zip(labels,x1,x2):\n",
    "        if per > 100:\n",
    "            per = 100\n",
    "        out[l] = np.around(per,decimals=5), num_per\n",
    "    if print_out:\n",
    "        table = columnar([[x,out[x][0],out[x][1]] for x in out], [\"Class Name\", \"Relative Accuracy(%)\", \"Difference in Num of Labels\"])\n",
    "        print(table)\n",
    "    return out, tot_num_labels_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Goal\n",
    "In this notebook, we will try to understand the features of a good text prompt. We will be using the flowers and the pets dataset to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroshot_classifier_baseline(classnames, templates):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            texts = [\n",
    "                template.format(classname) for template in templates\n",
    "            ]  # format with class\n",
    "            texts = clip.tokenize(texts).cuda()  # tokenize\n",
    "            class_embeddings = clip_model.encode_text(texts)  # embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_performance(d, print_out=True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    corr = []\n",
    "    tot = []\n",
    "    for el in d:\n",
    "        x.append((d[el][0]*100)/d[el][1])\n",
    "        labels.append(d[el][2])\n",
    "        corr.append(d[el][0])\n",
    "        tot.append(d[el][1])\n",
    "    idx = np.argsort(x)\n",
    "    x = np.array(x)[idx]\n",
    "    labels = np.array(labels)[idx]\n",
    "    corr = np.array(corr)[idx]\n",
    "    tot = np.array(tot)[idx]\n",
    "    out = {}\n",
    "    for l,per,c,t in zip(labels,x,corr,tot):\n",
    "        out[l] = [np.around(per,5),int(c),int(t)]\n",
    "    if print_out:\n",
    "        table = columnar([[l, o[0], o[1], o[2]] for l,o in out.items()], [\"Class Name\", \"Accuracy(%)\", \"Num Correct\", \"Total\"])\n",
    "        print(table)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6572d2490296407ebefe5e20f60fd2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a913e0e4c0f4f749a85bf0258cb76c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pets baseline performance:  82.33851185609157\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Class Name                |Accuracy(%)|Num Correct|Total|\n",
      "|========================================================|\n",
      "|Persian                   |0.0        |0          |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Ragdoll                   |9.0        |9          |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|newfoundland              |11.0       |11         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|boxer                     |40.40404   |40         |99   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Bengal                    |49.0       |49         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|american pit bull terrier |72.0       |72         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|staffordshire bull terrier|76.40449   |68         |89   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|British Shorthair         |79.0       |79         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|chihuahua                 |79.0       |79         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|english cocker spaniel    |81.0       |81         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|beagle                    |85.0       |85         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Birman                    |87.0       |87         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Maine Coon                |88.0       |88         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Sphynx                    |90.0       |90         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Egyptian Mau              |90.72165   |88         |97   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Abyssinian                |90.81633   |89         |98   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|havanese                  |92.0       |92         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Siamese                   |93.0       |93         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|great pyrenees            |93.0       |93         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|wheaten terrier           |94.0       |94         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|american bulldog          |95.0       |95         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|basset hound              |95.0       |95         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|saint bernard             |95.0       |95         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|keeshond                  |95.9596    |95         |99   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|english setter            |96.0       |96         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|japanese chin             |96.0       |96         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|leonberger                |96.0       |96         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Russian Blue              |96.0       |96         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|german shorthaired        |97.0       |97         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|pomeranian                |97.0       |97         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|pug                       |97.0       |97         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|scottish terrier          |97.9798    |97         |99   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|miniature pinscher        |98.0       |98         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|samoyed                   |98.0       |98         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|shiba inu                 |99.0       |99         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|yorkshire terrier         |99.0       |99         |100  |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "|Bombay cat                |100.0      |88         |88   |\n",
      "|--------------------------|-----------|-----------|-----|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Persian': [0.0, 0, 100],\n",
       " 'Ragdoll': [9.0, 9, 100],\n",
       " 'newfoundland': [11.0, 11, 100],\n",
       " 'boxer': [40.40404, 40, 99],\n",
       " 'Bengal': [49.0, 49, 100],\n",
       " 'american pit bull terrier': [72.0, 72, 100],\n",
       " 'staffordshire bull terrier': [76.40449, 68, 89],\n",
       " 'British Shorthair': [79.0, 79, 100],\n",
       " 'chihuahua': [79.0, 79, 100],\n",
       " 'english cocker spaniel': [81.0, 81, 100],\n",
       " 'beagle': [85.0, 85, 100],\n",
       " 'Birman': [87.0, 87, 100],\n",
       " 'Maine Coon': [88.0, 88, 100],\n",
       " 'Sphynx': [90.0, 90, 100],\n",
       " 'Egyptian Mau': [90.72165, 88, 97],\n",
       " 'Abyssinian': [90.81633, 89, 98],\n",
       " 'havanese': [92.0, 92, 100],\n",
       " 'Siamese': [93.0, 93, 100],\n",
       " 'great pyrenees': [93.0, 93, 100],\n",
       " 'wheaten terrier': [94.0, 94, 100],\n",
       " 'american bulldog': [95.0, 95, 100],\n",
       " 'basset hound': [95.0, 95, 100],\n",
       " 'saint bernard': [95.0, 95, 100],\n",
       " 'keeshond': [95.9596, 95, 99],\n",
       " 'english setter': [96.0, 96, 100],\n",
       " 'japanese chin': [96.0, 96, 100],\n",
       " 'leonberger': [96.0, 96, 100],\n",
       " 'Russian Blue': [96.0, 96, 100],\n",
       " 'german shorthaired': [97.0, 97, 100],\n",
       " 'pomeranian': [97.0, 97, 100],\n",
       " 'pug': [97.0, 97, 100],\n",
       " 'scottish terrier': [97.9798, 97, 99],\n",
       " 'miniature pinscher': [98.0, 98, 100],\n",
       " 'samoyed': [98.0, 98, 100],\n",
       " 'shiba inu': [99.0, 99, 100],\n",
       " 'yorkshire terrier': [99.0, 99, 100],\n",
       " 'Bombay cat': [100.0, 88, 88]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance with just class names\n",
    "\n",
    "\n",
    "templates = [\"{}\"]\n",
    "\n",
    "classes = [c.replace(\"_\", \" \")for c in pets.classes]\n",
    "\n",
    "pets_baseline_zw = zeroshot_classifier_baseline(classes,templates)\n",
    "\n",
    "pets_baseline_czs = clip_zero_shot(\n",
    "    p_test_loader,\n",
    "    classes,\n",
    "    pets_baseline_zw\n",
    ")\n",
    "print(\"Pets baseline performance: \",pets_baseline_czs[0])\n",
    "per_class_performance(pets_baseline_czs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a35e12a1e4da1bdba69168d7e00f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c5f3e0476f4f7a811c5ebf2acae1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e925e4d72840ba971ddffbc64cf1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2321d8f6122b4a1183b62593508d4af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-80ca789cbded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpets_zw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeroshot_classifier_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     pets_czs = clip_zero_shot(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mp_test_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-fdc382fefbf9>\u001b[0m in \u001b[0;36mclip_zero_shot\u001b[0;34m(loader, classes, zeroshot_weights, clip_model_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "templates = [\"{}\",\n",
    "             \"a {}\",\n",
    "             \"is a {}\",\n",
    "             \"This is a {}\",\n",
    "             \"This is a {}.\",\n",
    "             \"a is this {}.\",\n",
    "             \"is a this {}.\",\n",
    "             \"That is a {}.\",\n",
    "             \"That is a {} which is a very wonderful and cute pet to have, we love it very much.\",\n",
    "             \"This is a photo of a {}\", \n",
    "             \"This is a photo of a {}, a pet\", \n",
    "             \"house pet cute {}\"]\n",
    "out = []\n",
    "for template in templates:\n",
    "    \n",
    "    t = [template]\n",
    "\n",
    "    pets_zw = zeroshot_classifier_baseline(classes,t)\n",
    "\n",
    "    pets_czs = clip_zero_shot(\n",
    "        p_test_loader,\n",
    "        classes,\n",
    "        pets_zw\n",
    "    )\n",
    "    out.append(pets_czs[0])\n",
    "    \n",
    "for t,o in zip(templates,out):\n",
    "    print(f\"{t}: {o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669c49f5e50a42e3a4cd732700ec9fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02043e365a4f4d0eb61ed85e0483c8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a {}, a pet {}: 86.91741618969746\n"
     ]
    }
   ],
   "source": [
    "def zeroshot_classifier_1(classnames, templates):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            if classname[0].isupper():\n",
    "                animal = \"dog\"\n",
    "            else:\n",
    "                animal = \"cat\"\n",
    "            texts = [\n",
    "                template.format(classname, animal) for template in templates\n",
    "            ]  # format with class\n",
    "            texts = clip.tokenize(texts).cuda()  # tokenize\n",
    "            class_embeddings = clip_model.encode_text(texts)  # embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights\n",
    "templates = [\"This is a {}, a pet {}\"]\n",
    "out = []\n",
    "for template in templates:\n",
    "             \n",
    "    \n",
    "    t = [template]\n",
    "\n",
    "    pets_zw = zeroshot_classifier_1(classes,t)\n",
    "\n",
    "    pets_czs = clip_zero_shot(\n",
    "        p_test_loader,\n",
    "        classes,\n",
    "        pets_zw\n",
    "    )\n",
    "    out.append(pets_czs[0])\n",
    "    \n",
    "for t,o in zip(templates,out):\n",
    "    print(f\"{t}: {o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
