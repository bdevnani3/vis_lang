{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function clip.clip.load(name: str, device: Union[str, torch.device] = 'cpu', jit=True)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "## CIFAR-100 Test\n",
    "\n",
    "# Download the dataset\n",
    "\n",
    "cifar100 = CIFAR100(root=\"/nethome/bdevnani3/raid/data/\", download=True, train=False)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "top_1_accuracy = 0\n",
    "top_5_accuracy = 0\n",
    "\n",
    "per_class_accuracy_top1 = { k:[0,0] for k in range(100)} # correct, total\n",
    "per_class_accuracy_top5 = { k:[0,0] for k in range(100)} # correct, total\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "for i in range(10000):\n",
    "    if i%100 ==0:\n",
    "        print(i)\n",
    "\n",
    "    # Prepare the inputs\n",
    "    image, class_id = cifar100[i]\n",
    "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "\n",
    "    # Pick the top 5 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(5)\n",
    "\n",
    "    if indices[0] == class_id:\n",
    "        top_1_accuracy +=1\n",
    "        per_class_accuracy_top1[class_id][0] +=1\n",
    "\n",
    "    if class_id in indices:\n",
    "        top_5_accuracy +=1\n",
    "        per_class_accuracy_top5[class_id][0] +=1\n",
    "\n",
    "    per_class_accuracy_top1[class_id][1] +=1\n",
    "    per_class_accuracy_top5[class_id][1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_1_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d526a769c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_1_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'top_1_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "top_1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "## Flowers test\n",
    "\n",
    "flowers = datasets.ImageFolder(\"/nethome/bdevnani3/raid/data/test\")\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in flowers.classes]).to(device)\n",
    "\n",
    "top_1_accuracy = 0\n",
    "top_5_accuracy = 0\n",
    "\n",
    "per_class_accuracy_top1 = { k:[0,0] for k in range(102)} # correct, total\n",
    "per_class_accuracy_top5 = { k:[0,0] for k in range(102)} # correct, total\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "for i in range(len(flowers)):\n",
    "    if i%100 ==0:\n",
    "        print(i)\n",
    "\n",
    "    # Prepare the inputs\n",
    "    image, class_id = flowers[i]\n",
    "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "\n",
    "    # Pick the top 5 most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(5)\n",
    "\n",
    "    if indices[0] == class_id:\n",
    "        top_1_accuracy +=1\n",
    "        per_class_accuracy_top1[class_id][0] +=1\n",
    "\n",
    "    if class_id in indices:\n",
    "        top_5_accuracy +=1\n",
    "        per_class_accuracy_top5[class_id][0] +=1\n",
    "\n",
    "    per_class_accuracy_top1[class_id][1] +=1\n",
    "    per_class_accuracy_top5[class_id][1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:44,  2.66s/it]\u001b[A\n",
      " 47%|████▋     | 236/500 [10:27<11:36,  2.64s/it]\u001b[A\n",
      " 47%|████▋     | 237/500 [10:30<11:30,  2.63s/it]\u001b[A\n",
      " 48%|████▊     | 238/500 [10:32<11:29,  2.63s/it]\u001b[A\n",
      " 48%|████▊     | 239/500 [10:35<11:28,  2.64s/it]\u001b[A\n",
      " 48%|████▊     | 240/500 [10:38<11:26,  2.64s/it]\u001b[A\n",
      " 48%|████▊     | 241/500 [10:40<11:27,  2.65s/it]\u001b[A\n",
      " 48%|████▊     | 242/500 [10:43<11:31,  2.68s/it]\u001b[A\n",
      " 49%|████▊     | 243/500 [10:46<11:27,  2.67s/it]\u001b[A\n",
      " 49%|████▉     | 244/500 [10:48<11:21,  2.66s/it]\u001b[A\n",
      " 49%|████▉     | 245/500 [10:51<11:18,  2.66s/it]\u001b[A\n",
      " 49%|████▉     | 246/500 [10:54<11:15,  2.66s/it]\u001b[A\n",
      " 49%|████▉     | 247/500 [10:56<11:11,  2.65s/it]\u001b[A\n",
      " 50%|████▉     | 248/500 [10:59<11:08,  2.65s/it]\u001b[A\n",
      " 50%|████▉     | 249/500 [11:01<11:04,  2.65s/it]\u001b[A\n",
      " 50%|█████     | 250/500 [11:04<11:02,  2.65s/it]\u001b[A\n",
      " 50%|█████     | 251/500 [11:07<10:59,  2.65s/it]\u001b[A\n",
      " 50%|█████     | 252/500 [11:09<10:57,  2.65s/it]\u001b[A\n",
      " 51%|█████     | 253/500 [11:12<10:54,  2.65s/it]\u001b[A\n",
      " 51%|█████     | 254/500 [11:15<10:51,  2.65s/it]\u001b[A\n",
      " 51%|█████     | 255/500 [11:17<10:48,  2.65s/it]\u001b[A\n",
      " 51%|█████     | 256/500 [11:20<10:45,  2.65s/it]\u001b[A\n",
      " 51%|█████▏    | 257/500 [11:23<10:43,  2.65s/it]\u001b[A\n",
      " 52%|█████▏    | 258/500 [11:25<10:44,  2.66s/it]\u001b[A\n",
      " 52%|█████▏    | 259/500 [11:28<10:45,  2.68s/it]\u001b[A\n",
      " 52%|█████▏    | 260/500 [11:31<10:38,  2.66s/it]\u001b[A\n",
      " 52%|█████▏    | 261/500 [11:33<10:34,  2.66s/it]\u001b[A\n",
      " 52%|█████▏    | 262/500 [11:36<10:29,  2.64s/it]\u001b[A\n",
      " 53%|█████▎    | 263/500 [11:39<10:23,  2.63s/it]\u001b[A\n",
      " 53%|█████▎    | 264/500 [11:41<10:21,  2.64s/it]\u001b[A\n",
      " 53%|█████▎    | 265/500 [11:44<10:19,  2.64s/it]\u001b[A\n",
      " 53%|█████▎    | 266/500 [11:46<10:17,  2.64s/it]\u001b[A\n",
      " 53%|█████▎    | 267/500 [11:49<10:14,  2.64s/it]\u001b[A\n",
      " 54%|█████▎    | 268/500 [11:52<10:12,  2.64s/it]\u001b[A\n",
      " 54%|█████▍    | 269/500 [11:54<10:09,  2.64s/it]\u001b[A\n",
      " 54%|█████▍    | 270/500 [11:57<10:06,  2.64s/it]\u001b[A\n",
      " 54%|█████▍    | 271/500 [12:00<10:04,  2.64s/it]\u001b[A\n",
      " 54%|█████▍    | 272/500 [12:02<10:01,  2.64s/it]\u001b[A\n",
      " 55%|█████▍    | 273/500 [12:05<09:58,  2.64s/it]\u001b[A\n",
      " 55%|█████▍    | 274/500 [12:08<09:55,  2.64s/it]\u001b[A\n",
      " 55%|█████▌    | 275/500 [12:10<09:55,  2.65s/it]\u001b[A\n",
      " 55%|█████▌    | 276/500 [12:13<09:56,  2.66s/it]\u001b[A\n",
      " 55%|█████▌    | 277/500 [12:16<09:52,  2.66s/it]\u001b[A\n",
      " 56%|█████▌    | 278/500 [12:18<09:49,  2.65s/it]\u001b[A\n",
      " 56%|█████▌    | 279/500 [12:21<09:45,  2.65s/it]\u001b[A\n",
      " 56%|█████▌    | 280/500 [12:24<09:42,  2.65s/it]\u001b[A\n",
      " 56%|█████▌    | 281/500 [12:26<09:39,  2.64s/it]\u001b[A\n",
      " 56%|█████▋    | 282/500 [12:29<09:36,  2.64s/it]\u001b[A\n",
      " 57%|█████▋    | 283/500 [12:31<09:33,  2.64s/it]\u001b[A\n",
      " 57%|█████▋    | 284/500 [12:34<09:31,  2.65s/it]\u001b[A\n",
      " 57%|█████▋    | 285/500 [12:37<09:29,  2.65s/it]\u001b[A\n",
      " 57%|█████▋    | 286/500 [12:39<09:26,  2.65s/it]\u001b[A\n",
      " 57%|█████▋    | 287/500 [12:42<09:22,  2.64s/it]\u001b[A\n",
      " 58%|█████▊    | 288/500 [12:45<09:17,  2.63s/it]\u001b[A\n",
      " 58%|█████▊    | 289/500 [12:47<09:14,  2.63s/it]\u001b[A\n",
      " 58%|█████▊    | 290/500 [12:50<09:13,  2.63s/it]\u001b[A\n",
      " 58%|█████▊    | 291/500 [12:53<09:11,  2.64s/it]\u001b[A\n",
      " 58%|█████▊    | 292/500 [12:55<09:10,  2.65s/it]\u001b[A\n",
      " 59%|█████▊    | 293/500 [12:58<09:06,  2.64s/it]\u001b[A\n",
      " 59%|█████▉    | 294/500 [13:00<09:04,  2.64s/it]\u001b[A\n",
      " 59%|█████▉    | 295/500 [13:03<09:01,  2.64s/it]\u001b[A\n",
      " 59%|█████▉    | 296/500 [13:06<08:58,  2.64s/it]\u001b[A\n",
      " 59%|█████▉    | 297/500 [13:08<08:56,  2.64s/it]\u001b[A\n",
      " 60%|█████▉    | 298/500 [13:11<08:53,  2.64s/it]\u001b[A\n",
      " 60%|█████▉    | 299/500 [13:14<08:50,  2.64s/it]\u001b[A\n",
      " 60%|██████    | 300/500 [13:16<08:48,  2.64s/it]\u001b[A\n",
      " 60%|██████    | 301/500 [13:19<08:48,  2.66s/it]\u001b[A\n",
      " 60%|██████    | 302/500 [13:22<08:53,  2.69s/it]\u001b[A\n",
      " 61%|██████    | 303/500 [13:24<08:48,  2.68s/it]\u001b[A\n",
      " 61%|██████    | 304/500 [13:27<08:43,  2.67s/it]\u001b[A\n",
      " 61%|██████    | 305/500 [13:30<08:40,  2.67s/it]\u001b[A\n",
      " 61%|██████    | 306/500 [13:32<08:36,  2.66s/it]\u001b[A\n",
      " 61%|██████▏   | 307/500 [13:35<08:31,  2.65s/it]\u001b[A\n",
      " 62%|██████▏   | 308/500 [13:38<08:26,  2.64s/it]\u001b[A\n",
      " 62%|██████▏   | 309/500 [13:40<08:24,  2.64s/it]\u001b[A\n",
      " 62%|██████▏   | 310/500 [13:43<08:22,  2.65s/it]\u001b[A\n",
      " 62%|██████▏   | 311/500 [13:46<08:20,  2.65s/it]\u001b[A\n",
      " 62%|██████▏   | 312/500 [13:48<08:18,  2.65s/it]\u001b[A\n",
      " 63%|██████▎   | 313/500 [13:51<08:15,  2.65s/it]\u001b[A\n",
      " 63%|██████▎   | 314/500 [13:54<08:14,  2.66s/it]\u001b[A\n",
      " 63%|██████▎   | 315/500 [13:56<08:12,  2.66s/it]\u001b[A\n",
      " 63%|██████▎   | 316/500 [13:59<08:11,  2.67s/it]\u001b[A\n",
      " 63%|██████▎   | 317/500 [14:02<08:08,  2.67s/it]\u001b[A\n",
      " 64%|██████▎   | 318/500 [14:04<08:05,  2.67s/it]\u001b[A\n",
      " 64%|██████▍   | 319/500 [14:07<08:02,  2.67s/it]\u001b[A\n",
      " 64%|██████▍   | 320/500 [14:10<07:58,  2.66s/it]\u001b[A\n",
      " 64%|██████▍   | 321/500 [14:12<07:54,  2.65s/it]\u001b[A\n",
      " 64%|██████▍   | 322/500 [14:15<07:51,  2.65s/it]\u001b[A\n",
      " 65%|██████▍   | 323/500 [14:18<07:48,  2.64s/it]\u001b[A\n",
      " 65%|██████▍   | 324/500 [14:20<07:45,  2.65s/it]\u001b[A\n",
      " 65%|██████▌   | 325/500 [14:23<07:42,  2.64s/it]\u001b[A\n",
      " 65%|██████▌   | 326/500 [14:25<07:39,  2.64s/it]\u001b[A\n",
      " 65%|██████▌   | 327/500 [14:28<07:36,  2.64s/it]\u001b[A\n",
      " 66%|██████▌   | 328/500 [14:31<07:33,  2.64s/it]\u001b[A\n",
      " 66%|██████▌   | 329/500 [14:33<07:28,  2.62s/it]\u001b[A\n",
      " 66%|██████▌   | 330/500 [14:36<07:26,  2.63s/it]\u001b[A\n",
      " 66%|██████▌   | 331/500 [14:39<07:25,  2.64s/it]\u001b[A\n",
      " 66%|██████▋   | 332/500 [14:41<07:26,  2.66s/it]\u001b[A\n",
      " 67%|██████▋   | 333/500 [14:44<07:23,  2.66s/it]\u001b[A\n",
      " 67%|██████▋   | 334/500 [14:47<07:19,  2.65s/it]\u001b[A\n",
      " 67%|██████▋   | 335/500 [14:49<07:16,  2.64s/it]\u001b[A\n",
      " 67%|██████▋   | 336/500 [14:52<07:12,  2.64s/it]\u001b[A\n",
      " 67%|██████▋   | 337/500 [14:54<07:10,  2.64s/it]\u001b[A\n",
      " 68%|██████▊   | 338/500 [14:57<07:08,  2.64s/it]\u001b[A\n",
      " 68%|██████▊   | 339/500 [15:00<07:05,  2.64s/it]\u001b[A\n",
      " 68%|██████▊   | 340/500 [15:02<07:02,  2.64s/it]\u001b[A\n",
      " 68%|██████▊   | 341/500 [15:05<07:00,  2.64s/it]\u001b[A\n",
      " 68%|██████▊   | 342/500 [15:08<06:58,  2.65s/it]\u001b[A\n",
      " 69%|██████▊   | 343/500 [15:10<06:55,  2.65s/it]\u001b[A\n",
      " 69%|██████▉   | 344/500 [15:13<06:52,  2.64s/it]\u001b[A\n",
      " 69%|██████▉   | 345/500 [15:16<06:48,  2.63s/it]\u001b[A\n",
      " 69%|██████▉   | 346/500 [15:18<06:45,  2.63s/it]\u001b[A\n",
      " 69%|██████▉   | 347/500 [15:21<06:47,  2.66s/it]\u001b[A\n",
      " 70%|██████▉   | 348/500 [15:24<06:44,  2.66s/it]\u001b[A\n",
      " 70%|██████▉   | 349/500 [15:26<06:41,  2.66s/it]\u001b[A\n",
      " 70%|███████   | 350/500 [15:29<06:38,  2.66s/it]\u001b[A\n",
      " 70%|███████   | 351/500 [15:32<06:32,  2.64s/it]\u001b[A\n",
      " 70%|███████   | 352/500 [15:34<06:29,  2.63s/it]\u001b[A\n",
      " 71%|███████   | 353/500 [15:37<06:27,  2.63s/it]\u001b[A\n",
      " 71%|███████   | 354/500 [15:39<06:25,  2.64s/it]\u001b[A\n",
      " 71%|███████   | 355/500 [15:42<06:22,  2.64s/it]\u001b[A\n",
      " 71%|███████   | 356/500 [15:45<06:20,  2.64s/it]\u001b[A\n",
      " 71%|███████▏  | 357/500 [15:47<06:17,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 358/500 [15:50<06:15,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 359/500 [15:53<06:12,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 360/500 [15:55<06:09,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 361/500 [15:58<06:06,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 362/500 [16:01<06:05,  2.65s/it]\u001b[A\n",
      " 73%|███████▎  | 363/500 [16:03<06:04,  2.66s/it]\u001b[A\n",
      " 73%|███████▎  | 364/500 [16:06<06:02,  2.66s/it]\u001b[A\n",
      " 73%|███████▎  | 365/500 [16:09<05:56,  2.64s/it]\u001b[A\n",
      " 73%|███████▎  | 366/500 [16:11<05:53,  2.64s/it]\u001b[A\n",
      " 73%|███████▎  | 367/500 [16:14<05:48,  2.62s/it]\u001b[A\n",
      " 74%|███████▎  | 368/500 [16:16<05:45,  2.62s/it]\u001b[A\n",
      " 74%|███████▍  | 369/500 [16:19<05:41,  2.61s/it]\u001b[A\n",
      " 74%|███████▍  | 370/500 [16:22<05:39,  2.61s/it]\u001b[A\n",
      " 74%|███████▍  | 371/500 [16:24<05:36,  2.61s/it]\u001b[A\n",
      " 74%|███████▍  | 372/500 [16:27<05:35,  2.62s/it]\u001b[A\n",
      " 75%|███████▍  | 373/500 [16:29<05:33,  2.63s/it]\u001b[A\n",
      " 75%|███████▍  | 374/500 [16:32<05:31,  2.63s/it]\u001b[A\n",
      " 75%|███████▌  | 375/500 [16:35<05:29,  2.63s/it]\u001b[A\n",
      " 75%|███████▌  | 376/500 [16:37<05:26,  2.64s/it]\u001b[A\n",
      " 75%|███████▌  | 377/500 [16:40<05:24,  2.64s/it]\u001b[A\n",
      " 76%|███████▌  | 378/500 [16:43<05:21,  2.64s/it]\u001b[A\n",
      " 76%|███████▌  | 379/500 [16:45<05:20,  2.65s/it]\u001b[A\n",
      " 76%|███████▌  | 380/500 [16:48<05:18,  2.65s/it]\u001b[A\n",
      " 76%|███████▌  | 381/500 [16:51<05:16,  2.66s/it]\u001b[A\n",
      " 76%|███████▋  | 382/500 [16:53<05:13,  2.66s/it]\u001b[A\n",
      " 77%|███████▋  | 383/500 [16:56<05:10,  2.65s/it]\u001b[A\n",
      " 77%|███████▋  | 384/500 [16:59<05:08,  2.66s/it]\u001b[A\n",
      " 77%|███████▋  | 385/500 [17:01<05:06,  2.66s/it]\u001b[A\n",
      " 77%|███████▋  | 386/500 [17:04<05:03,  2.66s/it]\u001b[A\n",
      " 77%|███████▋  | 387/500 [17:07<05:00,  2.66s/it]\u001b[A\n",
      " 78%|███████▊  | 388/500 [17:09<04:58,  2.66s/it]\u001b[A\n",
      " 78%|███████▊  | 389/500 [17:12<04:55,  2.66s/it]\u001b[A\n",
      " 78%|███████▊  | 390/500 [17:15<04:51,  2.65s/it]\u001b[A\n",
      " 78%|███████▊  | 391/500 [17:17<04:48,  2.65s/it]\u001b[A\n",
      " 78%|███████▊  | 392/500 [17:20<04:46,  2.65s/it]\u001b[A\n",
      " 79%|███████▊  | 393/500 [17:22<04:42,  2.64s/it]\u001b[A\n",
      " 79%|███████▉  | 394/500 [17:25<04:39,  2.64s/it]\u001b[A\n",
      " 79%|███████▉  | 395/500 [17:28<04:37,  2.64s/it]\u001b[A\n",
      " 79%|███████▉  | 396/500 [17:30<04:34,  2.64s/it]\u001b[A\n",
      " 79%|███████▉  | 397/500 [17:33<04:32,  2.64s/it]\u001b[A\n",
      " 80%|███████▉  | 398/500 [17:36<04:29,  2.64s/it]\u001b[A\n",
      " 80%|███████▉  | 399/500 [17:38<04:26,  2.64s/it]\u001b[A\n",
      " 80%|████████  | 400/500 [17:41<04:23,  2.63s/it]\u001b[A\n",
      " 80%|████████  | 401/500 [17:44<04:22,  2.65s/it]\u001b[A\n",
      " 80%|████████  | 402/500 [17:46<04:21,  2.67s/it]\u001b[A\n",
      " 81%|████████  | 403/500 [17:49<04:18,  2.66s/it]\u001b[A\n",
      " 81%|████████  | 404/500 [17:52<04:15,  2.66s/it]\u001b[A\n",
      " 81%|████████  | 405/500 [17:54<04:12,  2.66s/it]\u001b[A\n",
      " 81%|████████  | 406/500 [17:57<04:10,  2.66s/it]\u001b[A\n",
      " 81%|████████▏ | 407/500 [18:00<04:07,  2.66s/it]\u001b[A\n",
      " 82%|████████▏ | 408/500 [18:02<04:04,  2.66s/it]\u001b[A\n",
      " 82%|████████▏ | 409/500 [18:05<04:01,  2.65s/it]\u001b[A\n",
      " 82%|████████▏ | 410/500 [18:08<03:58,  2.65s/it]\u001b[A\n",
      " 82%|████████▏ | 411/500 [18:10<03:55,  2.65s/it]\u001b[A\n",
      " 82%|████████▏ | 412/500 [18:13<03:53,  2.65s/it]\u001b[A\n",
      " 83%|████████▎ | 413/500 [18:16<03:50,  2.65s/it]\u001b[A\n",
      " 83%|████████▎ | 414/500 [18:18<03:47,  2.65s/it]\u001b[A\n",
      " 83%|████████▎ | 415/500 [18:21<03:44,  2.65s/it]\u001b[A\n",
      " 83%|████████▎ | 416/500 [18:23<03:42,  2.64s/it]\u001b[A\n",
      " 83%|████████▎ | 417/500 [18:26<03:39,  2.64s/it]\u001b[A\n",
      " 84%|████████▎ | 418/500 [18:29<03:36,  2.64s/it]\u001b[A\n",
      " 84%|████████▍ | 419/500 [18:31<03:35,  2.67s/it]\u001b[A\n",
      " 84%|████████▍ | 420/500 [18:34<03:32,  2.66s/it]\u001b[A\n",
      " 84%|████████▍ | 421/500 [18:37<03:29,  2.65s/it]\u001b[A\n",
      " 84%|████████▍ | 422/500 [18:39<03:26,  2.65s/it]\u001b[A\n",
      " 85%|████████▍ | 423/500 [18:42<03:23,  2.64s/it]\u001b[A\n",
      " 85%|████████▍ | 424/500 [18:45<03:20,  2.64s/it]\u001b[A\n",
      " 85%|████████▌ | 425/500 [18:47<03:18,  2.64s/it]\u001b[A\n",
      " 85%|████████▌ | 426/500 [18:50<03:15,  2.64s/it]\u001b[A\n",
      " 85%|████████▌ | 427/500 [18:53<03:13,  2.64s/it]\u001b[A\n",
      " 86%|████████▌ | 428/500 [18:55<03:10,  2.65s/it]\u001b[A\n",
      " 86%|████████▌ | 429/500 [18:58<03:07,  2.64s/it]\u001b[A\n",
      " 86%|████████▌ | 430/500 [19:01<03:04,  2.64s/it]\u001b[A\n",
      " 86%|████████▌ | 431/500 [19:03<03:02,  2.64s/it]\u001b[A\n",
      " 86%|████████▋ | 432/500 [19:06<02:59,  2.64s/it]\u001b[A\n",
      " 87%|████████▋ | 433/500 [19:08<02:57,  2.64s/it]\u001b[A\n",
      " 87%|████████▋ | 434/500 [19:11<02:54,  2.64s/it]\u001b[A\n",
      " 87%|████████▋ | 435/500 [19:14<02:52,  2.65s/it]\u001b[A\n",
      " 87%|████████▋ | 436/500 [19:16<02:51,  2.67s/it]\u001b[A\n",
      " 87%|████████▋ | 437/500 [19:19<02:47,  2.67s/it]\u001b[A\n",
      " 88%|████████▊ | 438/500 [19:22<02:45,  2.66s/it]\u001b[A\n",
      " 88%|████████▊ | 439/500 [19:24<02:42,  2.66s/it]\u001b[A\n",
      " 88%|████████▊ | 440/500 [19:27<02:39,  2.66s/it]\u001b[A\n",
      " 88%|████████▊ | 441/500 [19:30<02:36,  2.65s/it]\u001b[A\n",
      " 88%|████████▊ | 442/500 [19:32<02:33,  2.65s/it]\u001b[A\n",
      " 89%|████████▊ | 443/500 [19:35<02:30,  2.65s/it]\u001b[A\n",
      " 89%|████████▉ | 444/500 [19:38<02:28,  2.65s/it]\u001b[A\n",
      " 89%|████████▉ | 445/500 [19:40<02:24,  2.63s/it]\u001b[A\n",
      " 89%|████████▉ | 446/500 [19:43<02:21,  2.62s/it]\u001b[A\n",
      " 89%|████████▉ | 447/500 [19:45<02:19,  2.63s/it]\u001b[A\n",
      " 90%|████████▉ | 448/500 [19:48<02:16,  2.63s/it]\u001b[A\n",
      " 90%|████████▉ | 449/500 [19:51<02:14,  2.63s/it]\u001b[A\n",
      " 90%|█████████ | 450/500 [19:53<02:12,  2.64s/it]\u001b[A\n",
      " 90%|█████████ | 451/500 [19:56<02:09,  2.65s/it]\u001b[A\n",
      " 90%|█████████ | 452/500 [19:59<02:07,  2.65s/it]\u001b[A\n",
      " 91%|█████████ | 453/500 [20:01<02:04,  2.65s/it]\u001b[A\n",
      " 91%|█████████ | 454/500 [20:04<02:02,  2.67s/it]\u001b[A\n",
      " 91%|█████████ | 455/500 [20:07<01:59,  2.66s/it]\u001b[A\n",
      " 91%|█████████ | 456/500 [20:09<01:56,  2.65s/it]\u001b[A\n",
      " 91%|█████████▏| 457/500 [20:12<01:53,  2.65s/it]\u001b[A\n",
      " 92%|█████████▏| 458/500 [20:15<01:50,  2.64s/it]\u001b[A\n",
      " 92%|█████████▏| 459/500 [20:17<01:48,  2.64s/it]\u001b[A\n",
      " 92%|█████████▏| 460/500 [20:20<01:45,  2.64s/it]\u001b[A\n",
      " 92%|█████████▏| 461/500 [20:23<01:42,  2.64s/it]\u001b[A\n",
      " 92%|█████████▏| 462/500 [20:25<01:40,  2.64s/it]\u001b[A\n",
      " 93%|█████████▎| 463/500 [20:28<01:37,  2.64s/it]\u001b[A\n",
      " 93%|█████████▎| 464/500 [20:30<01:34,  2.64s/it]\u001b[A\n",
      " 93%|█████████▎| 465/500 [20:33<01:32,  2.64s/it]\u001b[A\n",
      " 93%|█████████▎| 466/500 [20:36<01:29,  2.64s/it]\u001b[A\n",
      " 93%|█████████▎| 467/500 [20:38<01:27,  2.65s/it]\u001b[A\n",
      " 94%|█████████▎| 468/500 [20:41<01:24,  2.64s/it]\u001b[A\n",
      " 94%|█████████▍| 469/500 [20:44<01:21,  2.64s/it]\u001b[A\n",
      " 94%|█████████▍| 470/500 [20:46<01:19,  2.64s/it]\u001b[A\n",
      " 94%|█████████▍| 471/500 [20:49<01:16,  2.64s/it]\u001b[A\n",
      " 94%|█████████▍| 472/500 [20:52<01:13,  2.64s/it]\u001b[A\n",
      " 95%|█████████▍| 473/500 [20:54<01:11,  2.64s/it]\u001b[A\n",
      " 95%|█████████▍| 474/500 [20:57<01:08,  2.64s/it]\u001b[A\n",
      " 95%|█████████▌| 475/500 [21:00<01:06,  2.64s/it]\u001b[A\n",
      " 95%|█████████▌| 476/500 [21:02<01:03,  2.64s/it]\u001b[A\n",
      " 95%|█████████▌| 477/500 [21:05<01:00,  2.64s/it]\u001b[A\n",
      " 96%|█████████▌| 478/500 [21:07<00:58,  2.64s/it]\u001b[A\n",
      " 96%|█████████▌| 479/500 [21:10<00:55,  2.64s/it]\u001b[A\n",
      " 96%|█████████▌| 480/500 [21:13<00:53,  2.66s/it]\u001b[A\n",
      " 96%|█████████▌| 481/500 [21:15<00:50,  2.65s/it]\u001b[A\n",
      " 96%|█████████▋| 482/500 [21:18<00:47,  2.65s/it]\u001b[A\n",
      " 97%|█████████▋| 483/500 [21:21<00:44,  2.64s/it]\u001b[A\n",
      " 97%|█████████▋| 484/500 [21:23<00:42,  2.64s/it]\u001b[A\n",
      " 97%|█████████▋| 485/500 [21:26<00:39,  2.64s/it]\u001b[A\n",
      " 97%|█████████▋| 486/500 [21:29<00:36,  2.64s/it]\u001b[A\n",
      " 97%|█████████▋| 487/500 [21:31<00:34,  2.64s/it]\u001b[A\n",
      " 98%|█████████▊| 488/500 [21:34<00:31,  2.63s/it]\u001b[A\n",
      " 98%|█████████▊| 489/500 [21:36<00:28,  2.63s/it]\u001b[A\n",
      " 98%|█████████▊| 490/500 [21:39<00:26,  2.63s/it]\u001b[A\n",
      " 98%|█████████▊| 491/500 [21:42<00:23,  2.63s/it]\u001b[A\n",
      " 98%|█████████▊| 492/500 [21:44<00:21,  2.63s/it]\u001b[A\n",
      " 99%|█████████▊| 493/500 [21:47<00:18,  2.64s/it]\u001b[A\n",
      " 99%|█████████▉| 494/500 [21:50<00:15,  2.64s/it]\u001b[A\n",
      " 99%|█████████▉| 495/500 [21:52<00:13,  2.64s/it]\u001b[A\n",
      " 99%|█████████▉| 496/500 [21:55<00:10,  2.64s/it]\u001b[A\n",
      " 99%|█████████▉| 497/500 [21:58<00:07,  2.64s/it]\u001b[A\n",
      "100%|█████████▉| 498/500 [22:00<00:05,  2.64s/it]\u001b[A\n",
      "100%|█████████▉| 499/500 [22:03<00:02,  2.65s/it]\u001b[A\n",
      "100%|██████████| 500/500 [22:06<00:00,  2.65s/it]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<04:38,  2.82s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:05<04:26,  2.72s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:08<04:29,  2.78s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:11<04:28,  2.80s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:13<04:20,  2.74s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:16<04:20,  2.77s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:19<04:19,  2.79s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:22<04:12,  2.75s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:24<04:13,  2.78s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:27<04:12,  2.80s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:30<04:05,  2.76s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:33<04:04,  2.78s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:36<04:03,  2.80s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:38<03:56,  2.75s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:41<03:56,  2.78s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:44<03:55,  2.81s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:47<03:48,  2.76s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:49<03:48,  2.78s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:52<03:47,  2.80s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:55<03:40,  2.76s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:58<03:39,  2.78s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [01:01<03:38,  2.80s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [01:03<03:31,  2.75s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [01:06<03:31,  2.78s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [01:09<03:30,  2.81s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [01:12<03:24,  2.76s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [01:14<03:22,  2.77s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:17<03:19,  2.76s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:20<03:12,  2.72s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:23<03:12,  2.75s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:25<03:10,  2.76s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:28<03:04,  2.71s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:31<03:01,  2.72s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:33<02:59,  2.72s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:36<02:55,  2.70s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:39<02:55,  2.74s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:42<02:54,  2.77s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:44<02:49,  2.73s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:47<02:48,  2.76s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:50<02:47,  2.79s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:53<02:42,  2.75s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:56<02:40,  2.77s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:58<02:38,  2.78s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [02:01<02:32,  2.73s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [02:04<02:30,  2.74s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [02:07<02:27,  2.74s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [02:09<02:23,  2.70s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [02:12<02:21,  2.71s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [02:15<02:18,  2.72s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [02:17<02:14,  2.70s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [02:20<02:13,  2.73s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [02:23<02:12,  2.76s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [02:26<02:08,  2.72s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [02:28<02:06,  2.75s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [02:31<02:04,  2.76s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:34<01:59,  2.73s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:37<01:58,  2.75s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:39<01:56,  2.77s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:42<01:51,  2.73s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:45<01:50,  2.75s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:48<01:48,  2.77s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:50<01:43,  2.73s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:53<01:42,  2.76s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:56<01:40,  2.78s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:59<01:36,  2.75s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [03:01<01:34,  2.77s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [03:04<01:31,  2.78s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [03:07<01:27,  2.73s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [03:10<01:24,  2.74s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [03:12<01:22,  2.75s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [03:15<01:18,  2.72s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [03:18<01:16,  2.75s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [03:21<01:14,  2.76s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [03:23<01:10,  2.73s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [03:26<01:08,  2.75s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [03:29<01:06,  2.76s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [03:32<01:02,  2.72s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [03:34<01:00,  2.74s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [03:37<00:57,  2.76s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [03:40<00:54,  2.72s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [03:42<00:51,  2.73s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [03:45<00:49,  2.76s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [03:48<00:46,  2.72s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [03:51<00:44,  2.76s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:54<00:41,  2.78s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:56<00:38,  2.74s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:59<00:35,  2.76s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [04:02<00:33,  2.78s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [04:05<00:30,  2.75s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [04:07<00:27,  2.77s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [04:10<00:25,  2.78s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [04:13<00:21,  2.74s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [04:16<00:19,  2.76s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [04:18<00:16,  2.78s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [04:21<00:13,  2.74s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [04:24<00:11,  2.76s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [04:27<00:08,  2.77s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [04:29<00:05,  2.73s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [04:32<00:02,  2.74s/it]\u001b[A\n",
      "100%|██████████| 100/100 [04:35<00:00,  2.75s/it]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "Accuracy = 79.900\n",
      "/nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.3min finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load the dataset\n",
    "root = os.path.expanduser(\"/nethome/bdevnani3/raid/data/\")\n",
    "train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
    "test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
    "\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train)\n",
    "test_features, test_labels = get_features(test)\n",
    "\n",
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 79.900\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "### Feature Extractor\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root = os.path.expanduser(\"/nethome/bdevnani3/raid/data/\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train = CIFAR100(root, download=True, train=True, transform=transform)\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True, num_workers=4)\n",
    "test = CIFAR100(root, download=True, train=False, transform=transform)\n",
    "test_loader = DataLoader(test, batch_size=100, shuffle=True, num_workers=4)\n",
    "\n",
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "model_conv.eval()\n",
    "\n",
    "def get_features(data_loader):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for inps, labels in data_loader:\n",
    "        with torch.no_grad():\n",
    "            features = model_conv(inps)\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_features(train_loader)\n",
    "test_features, test_labels = get_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "Accuracy = 42.710\n",
      "/nethome/bdevnani3/anaconda3/envs/p3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 14.3min finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "cifar100 = CIFAR100(root=\"/nethome/bdevnani3/raid/data/\", download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'transform', 'target_transform', 'transforms', 'train', 'data', 'targets', 'classes', 'class_to_idx'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6250aeecf667241d2415373c88b70d4f824c8a2781323a01ee2a69a098796f4a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "6250aeecf667241d2415373c88b70d4f824c8a2781323a01ee2a69a098796f4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
