{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179be41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import datasets\n",
    "importlib.reload(datasets)\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import *\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "import clip\n",
    "\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4410ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    global clip_model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataset):\n",
    "            features = clip_model.encode_image(images.to(device))\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features), torch.cat(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e180039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_clip_features(classes, prompt=\"a {} with petals.\"):\n",
    "    # Assumes the positions are in accordance to the label numbers\n",
    "    embedding_per_class = {}\n",
    "    \n",
    "    global clip_model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i,_class in enumerate(classes):\n",
    "            _class = _class.replace(\"_\", \" \")\n",
    "            text = clip.tokenize(prompt.format(_class)).cuda() \n",
    "            class_embeddings = clip_model.encode_text(\n",
    "                    text\n",
    "                )\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            embedding_per_class[i] = class_embeddings\n",
    "    return embedding_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "dataset_obj = Flowers102(0, 50)\n",
    "train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "test_loader = dataset_obj.get_test_loader(transform_fn=clip_preprocess)\n",
    "classes = dataset_obj.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545701b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_clip_features(train_loader)\n",
    "test_features, test_labels = get_clip_features(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0efa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46bea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(l):\n",
    "    return np.mean(l), np.var(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5fc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [\n",
    "        float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())\n",
    "        for k in topk\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1caf3",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1aa13",
   "metadata": {},
   "source": [
    "### Random Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ad6b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68be28e567c42c0bdcda8812d068d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9941bab6954664b5affdfb50e9aae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([19, 512])\n",
      "torch.Size([512, 102])\n",
      "num_classes: -1 acc: 1.9536019536019535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfff189f5f04927a5170d4465f18507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([19, 512])\n",
      "torch.Size([512, 102])\n",
      "num_classes: -1 acc: 1.8315018315018317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dfcaf1f34f4eeab6ad94d2f9e8c737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([19, 512])\n",
      "torch.Size([512, 102])\n",
      "num_classes: -1 acc: 1.221001221001221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33a23417faa45559951ab59faa8b761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([19, 512])\n",
      "torch.Size([512, 102])\n",
      "num_classes: -1 acc: 1.221001221001221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfe881a6b2b4de29e10a0d29bb9316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([512, 102])\n",
      "torch.Size([19, 512])\n",
      "torch.Size([512, 102])\n",
      "num_classes: -1 acc: 1.7094017094017095\n",
      "(1.5873015873015874, 0.09541401482793424)\n"
     ]
    }
   ],
   "source": [
    "# get zs weights \n",
    "out = []\n",
    "train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "train_featuress, train_labelss = get_clip_features(train_loader)\n",
    "for _ in range(iters):\n",
    "    for nc in [-1]:\n",
    "        train_features = train_featuress / train_featuress.norm(dim=-1, keepdim=True)\n",
    "        for _ in range(1):\n",
    "            embeddings = []\n",
    "            for c in range(len(classes)):\n",
    "                ind = random.choice((c == train_labels).nonzero(as_tuple=False).tolist())\n",
    "                embeddings.append(train_features[ind].cpu().numpy())\n",
    "\n",
    "            zeroshot_weights = torch.from_numpy(np.array(embeddings).squeeze(1).T).to(torch.float16)\n",
    "\n",
    "            def accuracy(output, target, topk=(1,)):\n",
    "                pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "                correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "                return [\n",
    "                    float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())\n",
    "                    for k in topk\n",
    "                ]\n",
    "\n",
    "            # lazy load\n",
    "            if clip_model == None:\n",
    "                clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                top1, top5, n = 0.0, 0.0, 0.0\n",
    "                for i, (images, target) in enumerate(tqdm(test_loader)):\n",
    "                    images = images.cuda()\n",
    "                    target = target.cuda()\n",
    "\n",
    "                    # predict\n",
    "\n",
    "                    image_features = clip_model.encode_image(images)\n",
    "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                    print(image_features.to(device).shape)\n",
    "                    print(zeroshot_weights.to(device).shape)\n",
    "                    logits = 100.0 * image_features.to(device) @ zeroshot_weights.to(device)\n",
    "\n",
    "                    # measure accuracy\n",
    "                    acc1, _ = accuracy(logits, target, topk=(1, 5))\n",
    "                    top1 += acc1\n",
    "                    n += images.size(0)\n",
    "\n",
    "            top1 = (top1 / n) * 100\n",
    "\n",
    "            print(\"num_classes:\", nc, \"acc:\", top1)\n",
    "            out.append(top1)\n",
    "print(get_stats(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcda77",
   "metadata": {},
   "source": [
    "### Average Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa7c302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5355fe5337c840e98c1a73df04123571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ac4f7f2806408caa442c09160730f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 73.26072607260727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963b387974c344bbb2d8fb562329ec2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c68c6b6c5b4e40a0a1db21a5843553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 73.26072607260727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17372f3a68d04412a639781285289eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70b61ddfc534d8eb75a87a9d2310ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 73.26072607260727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a573da2455494ca04114159fd3d1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa15b09746b84c37bee4931f4fc4fd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 73.26072607260727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf1959327ff42a4b1a68116e7ca8ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe49e3353a74170ab5f820d245fe261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 73.26072607260727\n",
      "(73.26072607260727, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# get zs weights \n",
    "for nc in [-1]:\n",
    "    \n",
    "    out = []\n",
    "    # train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess, num_elements_per_class=nc, shuffle=False)\n",
    "    # train_featuress, train_labelss = get_clip_features(train_loader)\n",
    "    for _ in range(iters):\n",
    "        train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess, num_elements_per_class=nc)\n",
    "        train_features, train_labels = get_clip_features(train_loader)\n",
    "        train_features /= train_features.norm(dim=-1, keepdim=True)\n",
    "        for _ in range(1):\n",
    "            embeddings = []\n",
    "            for c in range(len(classes)):\n",
    "                ind = (c == train_labels).nonzero(as_tuple=True)[0]\n",
    "                embeddings.append(torch.mean(train_features[ind],dim=0))\n",
    "#                 embeddings.append(np.mean(train_features[ind].cpu().numpy(), 0))\n",
    "\n",
    "#             zeroshot_weights = torch.from_numpy(np.array(embeddings).T).to(torch.float16)\n",
    "            \n",
    "            zeroshot_weights = torch.stack(embeddings).squeeze(1)\n",
    "            print(\"Done\")\n",
    "\n",
    "\n",
    "            # lazy load\n",
    "            if clip_model == None:\n",
    "                clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                top1, top5, n = 0.0, 0.0, 0.0\n",
    "                for i, (images, target) in enumerate(tqdm(test_loader)):\n",
    "                    images = images.cuda()\n",
    "                    target = target.cuda()\n",
    "\n",
    "                    # predict\n",
    "\n",
    "                    image_features = clip_model.encode_image(images)\n",
    "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                    logits = 100.0 * image_features.to(device) @ zeroshot_weights.to(device).T\n",
    "\n",
    "                    # measure accuracy\n",
    "                    acc1, _ = accuracy(logits, target, topk=(1, 5))\n",
    "                    top1 += acc1\n",
    "                    n += images.size(0)\n",
    "\n",
    "            top1 = (top1 / n) * 100\n",
    "            out.append(top1)\n",
    "            print(\"num_classes:\", nc, \"acc:\", top1)\n",
    "    print(get_stats(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8de48",
   "metadata": {},
   "source": [
    "### Nearest Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b19798f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceda3903b1b4e438b9d20c21a7a812c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e55a404106b41d0be9139e88dc77a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.25742574257426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc3d436bb734c74a66456bc7c0eb866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e244f82a474c4f8981ca499e48b12a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.25742574257426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a684f3ed86e947afb965c77772b18c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c6988adcdd4af5a07e7adec309d274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.25742574257426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2275526f1a1f4944b69b02212b3088a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c267965ebf4f369db3721c589123c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.25742574257426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a38d5173f24c408e47f735157203b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6fe45034c4de2bf1f1b337a7b1df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 74.25742574257426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74.25742574257426, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = []\n",
    "\n",
    "for _ in range(iters):\n",
    "    # Normalize all the training embeddings\n",
    "    train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "    train_features, train_labels = get_clip_features(train_loader)\n",
    "    train_features /= train_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # lazy load\n",
    "    if clip_model == None:\n",
    "        clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        top1, n = 0.0, 0.0\n",
    "        for i, (images, targets) in enumerate(tqdm(test_loader)):\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            # Load and normalize image features\n",
    "            image_features = clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            for image_feature, target in zip(image_features,targets):\n",
    "                # Dot product image feature with train features, find the maximum dot product(closest vector)\n",
    "                out = (image_feature @ train_features.t()).argmax(dim=-1)\n",
    "                closest = out.cpu().numpy()\n",
    "                prediction = train_labels[closest].cpu().numpy()\n",
    "\n",
    "                if target.cpu().numpy() == prediction:\n",
    "                    top1 +=1\n",
    "                n+=1\n",
    "\n",
    "    top1 = (top1 / n) * 100\n",
    "    final.append(top1)\n",
    "    print(\"acc:\", top1)\n",
    "\n",
    "get_stats(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2143811",
   "metadata": {},
   "source": [
    "### Average Text and Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2649abc7b0c7418cb47d0552af0697c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e054fe92504948a39b2b79893b400520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 1 acc: 54.04620462046205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3609a8e254044e12ab14e2e7f7abc052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c3c5f004f943c49c7ff9f747331d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 1 acc: 54.303630363036305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398612b4546a4d02b146609ed62d2fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2588c29a8142c68f696afc689e1d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 1 acc: 55.3003300330033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed79002a0434e0bac0fbf5593659549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4db8df24d14df5901f1847e3530e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 1 acc: 54.46864686468646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca4e2e1bd6c40a7a52f94b265600e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d666164f14ee1accfd135d670bab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 1 acc: 53.412541254125415\n",
      "(54.306270627062716, 0.3761827271836071)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79db25d6c0cb438ab65f78bf541e554e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0831b486a5d544d2a19f5381b953dce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2 acc: 60.33003300330033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cb4034279f4ea586dae2bdf24d1e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076d5ee281fd42549e25b276d3df8e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2 acc: 60.71287128712871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becbb24c460342e582dc455f6b3cb204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042ea40b73f4471dab0dbf57b1d81981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2 acc: 58.277227722772274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04952934de9f4a9e88ba6b9b71f53a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519eecb8b89b4cfbaf9f637d3eb4e98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2 acc: 59.07590759075908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e590f3ff279840dc94754f43c707cb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0d6367f2084473a4beb2bec48ce080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2 acc: 58.06600660066007\n",
      "(59.29240924092409, 1.1351810824646826)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ce878c7eb6486e8d02a8eb20baaf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8790ef5d8a843ada2f6e8c6ec5346b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 4 acc: 67.41254125412541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3967cc9e7e741048fd72638cbb1609b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa52643cfb247ae82f4fc3ed5a71fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 4 acc: 66.20462046204621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdb6e2cf9614443b610183fe2a9f476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7159ed5cce164e42b415c082789a3a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 4 acc: 65.32673267326733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c120554c245a4b3fbff91f7a8bd339e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24981391b5ee456487e61e8a26a8f946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 4 acc: 70.29702970297029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7655ebe6ae4c438cc0176caa480645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7433ea0d408a410faeec9ab0eb07baf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 4 acc: 67.86798679867987\n",
      "(67.42178217821781, 2.8673894716204194)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c460a5fb34403587e9f758d168b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7fa51811eb495580052fddafb14c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 8 acc: 71.36633663366337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bc57dc4df3407989dfbdd2d825bced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e62e1bb9a447291911487dd6f133f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 8 acc: 69.86138613861385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e95098af64e4b97954e036215a62721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488e513b0874495495a81f6b94fac216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 8 acc: 70.93069306930693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932370b948744bbb961c2baf9b839a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e037519119e4686b23c92241aeef50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 8 acc: 70.9108910891089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd46ff4e2f047658ab22ad765c031fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa72c837029d46bfb47e6053104daf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 8 acc: 70.44884488448845\n",
      "(70.7036303630363, 0.26159701118626855)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8689f1c70c437a8e641244bb3bb4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a8e62018f949bfb92110116580ced7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 16 acc: 74.8052805280528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae992ad605949fb8e0826bc2cafd099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d6eb79379e42308e65fc27606bed01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 16 acc: 73.59075907590758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c2a6190c12409ca9070d24f38cad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99371cb37c394048abe8f4fec8029e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 16 acc: 72.65346534653465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42798b19c69d43c8ac5f24064a91deb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e42e43d769b4ef982df7d26876a1b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 16 acc: 72.4026402640264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20199513d5b444f7a05e0d3f5ee5ad80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16904325edd4f3cae4610d8bdd1d0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 16 acc: 73.37293729372936\n",
      "(73.36501650165016, 0.7115711967236343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec40600eeb14ba18fc79f225d6d6daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8115c923c05e4e11b085856c24c04de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 76.73927392739273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89944739b0bc41bcbc5be0639187f18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe24aa3a31c54dfa92c9c222e8585e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 76.73927392739273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfde1d1ead064498b59f81ed82e6ae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_clip_features = get_text_clip_features(classes)\n",
    "for nc in [1,2,4,8,16,-1]:\n",
    "    \n",
    "    final = []\n",
    "    for _ in range(iters):\n",
    "        train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess, num_elements_per_class=nc)\n",
    "        train_features, train_labels = get_clip_features(train_loader)\n",
    "        train_features /= train_features.norm(dim=-1, keepdim=True)\n",
    "        for _ in range(1):\n",
    "            embeddings = []\n",
    "            for c in range(len(classes)):\n",
    "                ind = (c == train_labels).nonzero(as_tuple=True)[0]\n",
    "                image_embs = torch.mean(train_features[ind],dim=0)\n",
    "                text_embs = text_clip_features[c].squeeze()\n",
    "                avg_emb = 0.5*image_embs + 0.5*text_embs\n",
    "                embeddings.append(avg_emb)\n",
    "            \n",
    "            zeroshot_weights = torch.stack(embeddings).squeeze(1)\n",
    "\n",
    "            # lazy load\n",
    "            if clip_model == None:\n",
    "                clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                top1, top5, n = 0.0, 0.0, 0.0\n",
    "                for i, (images, target) in enumerate(tqdm(test_loader)):\n",
    "                    images = images.cuda()\n",
    "                    target = target.cuda()\n",
    "                    image_features = clip_model.encode_image(images)\n",
    "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                    # predict\n",
    "                    for image_feature,tar in zip(image_features, target):\n",
    "                        big = []m\n",
    "                        for c in range(len(classes)):\n",
    "                            text_embs = text_clip_features[c].squeeze()\n",
    "                            avg_emb = 0.5*image_feature + 0.5*text_embs\n",
    "                            big.append(avg_emb)\n",
    "                        big = torch.stack(big)\n",
    "                        dot = big @ zeroshot_weights.T\n",
    "                        out = np.unravel_index(torch.argmax(dot, axis=None).cpu().numpy(), dot.shape)[1]\n",
    "                        if tar.cpu().numpy() == out:\n",
    "                            top1 +=1\n",
    "                        n+=1\n",
    "\n",
    "\n",
    "\n",
    "            top1 = (top1 / n) * 100\n",
    "            final.append(top1)\n",
    "            print(\"num_classes:\", nc, \"acc:\", top1)\n",
    "    print(get_stats(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08569d8",
   "metadata": {},
   "source": [
    "## CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e448007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedc1058faff444dbd1cad8c11ccbd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 93.16239316239316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c039bdc3fc4842a0cc2d73da7459e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 93.16239316239316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.16239316239316, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = []\n",
    "\n",
    "iters = 2\n",
    "\n",
    "for _ in range(iters):\n",
    "    # Normalize all the training embeddings\n",
    "    train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "    train_features, train_labels = get_clip_features(train_loader)\n",
    "    train_features /= train_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    train_features_per_class = {i:[] for i in range(len(classes))}\n",
    "    for c in range(len(classes)):\n",
    "        ind = (c == train_labels).nonzero(as_tuple=True)[0]\n",
    "        class_image_embs = train_features[ind]\n",
    "        train_features_per_class[c].append(class_image_embs)\n",
    "                                                         \n",
    "    for c in range(len(classes)):\n",
    "        train_features_per_class[c] = torch.stack(train_features_per_class[c])\n",
    "                                                         \n",
    "    # lazy load\n",
    "    if clip_model == None:\n",
    "        clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        top1, n = 0.0, 0.0\n",
    "        for i, (images, targets) in enumerate(tqdm(test_loader)):\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            # Load and normalize image features\n",
    "            image_features = clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            for image_feature, target in zip(image_features,targets):\n",
    "                # Dot product image feature with train features, find the maximum dot product(closest vector)\n",
    "                prototype = []\n",
    "                for c in range(len(classes)):\n",
    "                    tf_c = train_features_per_class[c].squeeze(0)\n",
    "                    out = (image_feature @ tf_c.t()).argmax(dim=-1)\n",
    "                    closest = out.cpu().numpy()\n",
    "                    prototype.append(tf_c[closest])  \n",
    "                prototype = torch.stack(prototype)\n",
    "                out = (image_feature @ prototype.t()).argmax(dim=-1)\n",
    "                closest = out.cpu().numpy()\n",
    "                prediction = closest\n",
    "                \n",
    "                if target.cpu().numpy() == prediction:\n",
    "                    top1 +=1\n",
    "                n+=1\n",
    "\n",
    "    top1 = (top1 / n) * 100\n",
    "    final.append(top1)\n",
    "    print(\"acc:\", top1)\n",
    "\n",
    "get_stats(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82a4c3",
   "metadata": {},
   "source": [
    "### Appending image and text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clip_features = get_text_clip_features(classes)\n",
    "for nc in [-1]:\n",
    "    final = []\n",
    "    for _ in range(iters):\n",
    "        for _ in range(1):\n",
    "            embeddings = []\n",
    "            for c in range(len(classes)):\n",
    "                ind = (c == train_labels).nonzero(as_tuple=True)[0]\n",
    "                image_embs = torch.mean(train_features[ind],dim=0)\n",
    "                text_embs = text_clip_features[c].squeeze()\n",
    "                app_emb = torch.cat((image_embs, text_embs), 1)\n",
    "                embeddings.append(app_emb)\n",
    "            \n",
    "            zeroshot_weights = torch.stack(embeddings).squeeze(1)\n",
    "\n",
    "            # lazy load\n",
    "            if clip_model == None:\n",
    "                clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                top1, top5, n = 0.0, 0.0, 0.0\n",
    "                for i, (images, target) in enumerate(tqdm(test_loader)):\n",
    "                    images = images.cuda()\n",
    "                    target = target.cuda()\n",
    "                    image_features = clip_model.encode_image(images)\n",
    "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                    # predict\n",
    "                    for image_feature,tar in zip(image_features, target):\n",
    "                        big = []m\n",
    "                        for c in range(len(classes)):\n",
    "                            text_embs = text_clip_features[c].squeeze()\n",
    "                            app_emb = torch.cat((image_feature, text_embs), 1)\n",
    "                            big.append(app_emb)\n",
    "                        big = torch.stack(big)\n",
    "                        dot = big @ zeroshot_weights.T\n",
    "                        out = np.unravel_index(torch.argmax(dot, axis=None).cpu().numpy(), dot.shape)[1]\n",
    "                        if tar.cpu().numpy() == out:\n",
    "                            top1 +=1\n",
    "                        n+=1\n",
    "\n",
    "            top1 = (top1 / n) * 100\n",
    "            final.append(top1)\n",
    "            print(\"num_classes:\", nc, \"acc:\", top1)\n",
    "    print(get_stats(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944ed14",
   "metadata": {},
   "source": [
    "### Understanding the importance of Text embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3f92e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a2d1e471e64e6d9f2885dc02d36798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97323cea1b5242b497efa40df2a82613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 84.73748473748473\n",
      "0.1111111111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cac7dcc36214efd86ccd1c63eb08436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 86.93528693528694\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5e80dbdb464a79bbe9c471e9cf7277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 88.27838827838828\n",
      "0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0983c26b49c1442baa557c28cb8221eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 87.42368742368743\n",
      "0.4444444444444444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f86a1fd925946c48770e64a0fe719f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 86.08058608058609\n",
      "0.5555555555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef0e4a333c49db81b8b0f82aee95c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 84.85958485958486\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1bd887680e4d748f432d4501025252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 81.8070818070818\n",
      "0.7777777777777777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442b2ffaf12d42388a04fb506fa53d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 78.26617826617827\n",
      "0.8888888888888888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7462742231924473b496a2a0065dfdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 72.4053724053724\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f734ff34d6144b6aa467a8101f497e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: -1 acc: 66.30036630036629\n",
      "(81.7094017094017, 47.71833782822797)\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "dataset_obj = Flowers102(0, 50)\n",
    "train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess)\n",
    "test_loader = dataset_obj.get_test_loader(transform_fn=clip_preprocess)\n",
    "classes = dataset_obj.classes\n",
    "\n",
    "text_clip_features = get_text_clip_features(classes)\n",
    "for nc in [-1]:\n",
    "    train_loader, _ = dataset_obj.get_train_loaders(transform_fn=clip_preprocess, num_elements_per_class=nc, shuffle=False)\n",
    "    train_features, train_labels = get_clip_features(train_loader)\n",
    "    train_features /= train_features.norm(dim=-1, keepdim=True)\n",
    "    final = []\n",
    "    for lam in np.linspace(0.0, 1.0, 10):\n",
    "        print(lam)\n",
    "\n",
    "        for _ in range(1):\n",
    "            text_embeds = []\n",
    "            image_embeds = []\n",
    "            embeddings = []\n",
    "            for c in range(len(classes)):\n",
    "                ind = (c == train_labels).nonzero(as_tuple=True)[0]\n",
    "                image_embs = torch.mean(train_features[ind],dim=0)\n",
    "                text_embs = text_clip_features[c].squeeze()\n",
    "                text_embeds.append(text_embs)\n",
    "                image_embeds.append(image_embs)\n",
    "                avg_emb = (lam*image_embs + (1-lam)*text_embs)\n",
    "                embeddings.append(avg_emb)\n",
    "            \n",
    "            zeroshot_weights = torch.stack(embeddings).squeeze(1)\n",
    "            image_embeds = torch.stack(image_embeds).squeeze(1)\n",
    "            text_embeds = torch.stack(text_embeds).squeeze(1)\n",
    "\n",
    "            # lazy load\n",
    "            if clip_model == None:\n",
    "                clip_model, clip_preprocess = clip.load(clip_model_name, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                top1, top5, n = 0.0, 0.0, 0.0\n",
    "                for i, (images, target) in enumerate(tqdm(test_loader)):\n",
    "                    images = images.cuda()\n",
    "                    target = target.cuda()\n",
    "                    image_features = clip_model.encode_image(images)\n",
    "                    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                    # predict\n",
    "                    for image_feature,tar in zip(image_features, target):\n",
    "                        texts_per_img = []\n",
    "                        imgs_per_img = []\n",
    "                        for c in range(len(classes)):\n",
    "                            text_embs = text_clip_features[c].squeeze()\n",
    "#                             avg_emb = 0.25(image_feature@)\n",
    "                            texts_per_img.append(text_embs)\n",
    "                            imgs_per_img.append(image_feature)\n",
    "                        texts_per_img = torch.stack(texts_per_img)\n",
    "                        imgs_per_img = torch.stack(imgs_per_img)\n",
    "                        dot = lam*(imgs_per_img @ text_embeds.T) + (1-lam)*(imgs_per_img @ image_embeds.T) + 0*(texts_per_img @ text_embeds.T) + 0*(texts_per_img @ image_embeds.T)\n",
    "                        out = np.unravel_index(torch.argmax(dot, axis=None).cpu().numpy(), dot.shape)[1]\n",
    "                        if tar.cpu().numpy() == out:\n",
    "                            top1 +=1\n",
    "                        n+=1\n",
    "\n",
    "\n",
    "\n",
    "            top1 = (top1 / n) * 100\n",
    "            final.append(top1)\n",
    "            print(\"num_classes:\", nc, \"acc:\", top1)\n",
    "    print(get_stats(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e7a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
